{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "\n",
    "    * Support Vector Machines (SVMs) is linked to the concept of hyperplanes. A hyperplane is an $(n-1)$ subspace in an $n$-dimensional space. For example, to divide a three-dimensional space, we use a two-dimensional hyperplane (analogous to a 2D box).\n",
    "    * For a two-dimensional psace, the hyperplane becomes a line.\n",
    "    * SVMs classify data by finding the hyperplane which maximizes the margin between the different classes in the training dataset, and can be used for regression analysis, i.e. numerical predictions. \n",
    "    * Data points which reside along the margins are defined as support vectors and the mid-line passing in between of the margins is defined as the optimal hyperplane. \n",
    "    \n",
    "        <img src=\"data/images/SVM_concept.png\" width=\"30%\">\n",
    "        source: https://en.proft.me/2014/04/22/how-simulate-support-vector-machine-svm-r/\n",
    "        \n",
    "   \n",
    "2. Principles of SVMs\n",
    "    * Creates a boundary between data points (y-target which can be multi-dimensional) and the feature values.\n",
    "    * Uses kernel trick to first transform the available data and then use the transformed data to find an optimal boundary between the possible outputs\n",
    "    * Types of kernel functions:\n",
    "        * Linear kernel - no data transformation\n",
    "        * Polynomial kernel -  simple nonlinear transformation of the data by using a certain degree of $d$.\n",
    "        * Sigmoid kernel results in a SVM model somewhat analogous to a neural network using a sigmoid activation function.\n",
    "        * Gaussian Radial Basis Function (RBF) kernel is similar to a RBF neural network. \n",
    "\n",
    "For more information about the kernel functions, see http://www.jstatsoft.org/v15/i09/paper\n",
    "\n",
    "\n",
    "3. Advantages of SVMs\n",
    "    * Uses a regularisation parameter which makes over-fitting  unlikely.  \n",
    "    * Engineered kernel trick which incorporates domain knowledge. \n",
    "    * SVM is defined by a convex optimisation problem hence there is no local minima.\n",
    "\n",
    "\n",
    "4. Disadvantages of SVMs\n",
    "    * Depends only on the parameters for a given value of the regularisation parameter, kernel parameters and kernel function -> shift the over-fitting problem to model selection, hence results in over-fitting of model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# define model for use later\n",
    "svm_class_linear = Pipeline([(\"scaler\",StandardScaler()),(\"linear_svc\", LinearSVC(C=1, loss=\"hinge\")),])\n",
    "# C maintains a balance between the street width and margin violations\n",
    "# svm_class_linear = LinearSVC(random_state=0, tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "# loading in digits data\n",
    "dataset = load_digits()\n",
    "print(dataset.data.shape)\n",
    "\n",
    "X_digits = dataset.data / dataset.data.max() # to normalize all data by the maximum digit\n",
    "y_digits = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1437\n"
     ]
    }
   ],
   "source": [
    "# training and validation dataset\n",
    "# dummy_value = random.random() # generate a random number of between 0.0 and 1.0\n",
    "# print(round(dummy_value,3))\n",
    "dummy_value = 0.8\n",
    "size = len(X_digits)\n",
    "dummy_pos = int(dummy_value*size)\n",
    "print(dummy_pos)\n",
    "\n",
    "X_train = X_digits[:dummy_pos]\n",
    "y_train = y_digits[:dummy_pos]\n",
    "X_test = X_digits[dummy_pos:]\n",
    "y_test = y_digits[dummy_pos:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of matching ones is 319.\n",
      "The number of non-matching ones is 41.\n",
      "Average model accuracy is 88.6%.\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "result1 = svm_class_linear.fit(X_train,y_train)\n",
    "\n",
    "# model validation\n",
    "y_predict = result1.predict(X_test)\n",
    "y_test = np.array(y_test)\n",
    "y_test = y_test.reshape(len(y_test),-1)\n",
    "y_predict = np.array(y_predict)\n",
    "y_predict = y_predict.reshape(len(y_predict),-1)\n",
    "\n",
    "correct = 0\n",
    "wrong = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] == y_predict[i]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "print('The number of matching ones is ' + str(correct) + '.')\n",
    "print('The number of non-matching ones is ' + str(wrong) + '.')\n",
    "accuracy = (correct/(len(y_test))) * 100\n",
    "print('Average model accuracy is ' + str(round(accuracy,1)) + '%' + '.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
