{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN) - simple example with Google's \"Dogs and Cats\" datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "\n",
    "   * Convolutionary Neural Network (CNN) is commonly used for computer vision problems such as image classification, video summarization etc. \n",
    "   \n",
    "<img src=\"animal_data/images/CNN_generic.jpeg\" width=\"80%\">\n",
    "\n",
    "   source: https://www.superdatascience.com/convolutional-neural-networks-cnn-summary/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Steps to setting up a CNN model\n",
    "\n",
    "   In following sequence:\n",
    "\n",
    "    * Convolutional Operation (linear operation)\n",
    "        - Use of feature detectors \n",
    "        \n",
    "    * ReLu\n",
    "        - Replace all negative values in the feature maps by zero. Positive values are unchanged.\n",
    "        \n",
    "    * Pooling \n",
    "        - To achieve spatial invariance which is a situation whereby we can identify regardless of its orientation \n",
    "        - Comprises of maximum pooling, minimum pooling and average pooling\n",
    "        \n",
    "    * Flattening\n",
    "        - To detect more features from an image by using the pooled feature maps as the input into the densely connected NN\n",
    "        - Pooled feature maps exist in the form of 2D-arrays\n",
    "        - Flatten the pooled feature maps to become 1D-array as input into the densely connected NN\n",
    "        - For multiple pooled feature maps, they can be stacked together to form one long column vector\n",
    "        \n",
    "    * Fully connected layer\n",
    "        - To feed the flattened pooled feature maps into a densely connected neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Importing relevant packages, libraries and classes associated with python\n",
    "    \n",
    "    * pandas - Open Source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language https://pandas.pydata.org/\n",
    "    \n",
    "    * keras.models - Use of available models in keras. For more information, see https://keras.io/models/about-keras-models/#model-subclassing; https://keras.io/models/model/\n",
    "    \n",
    "    * keras.layers - Use of pooling, flattening tools etc. For more information, see https://keras.io/layers/core/\n",
    "    \n",
    "    * keras.preprocessing.image - Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches). For more information, see https://keras.io/preprocessing/image/\n",
    "    \n",
    "    * keras.optimizers -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Reading in data\n",
    "\n",
    "   * Using dogs and cats data from data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = ImageDataGenerator(rescale = 1./255, \n",
    "                                shear_range = 0.2, \n",
    "                                zoom_range = 0.2, \n",
    "                                horizontal_flip = True)\n",
    "test_data = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# For more information about the ImageDataGenerator function, \n",
    "# see https://keras.io/preprocessing/image/\n",
    "\n",
    "train_data_processed = train_data.flow_from_directory('animal_data/training_set',\n",
    "                                                       target_size= (64,64), \n",
    "                                                       batch_size=32, \n",
    "                                                       class_mode = 'binary')\n",
    "test_data_processed = train_data.flow_from_directory('animal_data/test_set',\n",
    "                                                      target_size= (64,64), \n",
    "                                                      batch_size=32, \n",
    "                                                      class_mode = 'binary')\n",
    "\n",
    "# target_size is the pixels of the pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Initialize CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Adding convolutional and pooling layers\n",
    "\n",
    "    * We are going to add two layers to our CNN model. Each layer contains one convolutional layer and one pooling layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First layer \n",
    "conv_layer1 = Conv2D(32,(3,3), input_shape = (64,64,3), activation = 'relu') \n",
    "# ***only have input_shape (64 x 64 is the pixels, 3 is the colors which are RBG) \n",
    "# for first layer, 32 filters\n",
    "# No input_shape for subsequent layers\n",
    "# For more information about the Conv2D function, see https://keras.io/layers/convolutional/\n",
    "cnn_model.add(conv_layer1)\n",
    "pool_layer1 = MaxPooling2D(pool_size = (2,2))\n",
    "# For more information about the MaxPooling2D function, see https://keras.io/layers/pooling/\n",
    "cnn_model.add(pool_layer1)\n",
    "\n",
    "# Second layer \n",
    "conv_layer2 = Conv2D( 32,(3,3), activation = 'relu')\n",
    "# For more information about the Conv2D function, see https://keras.io/layers/convolutional/\n",
    "cnn_model.add(conv_layer2)\n",
    "pool_layer2 = MaxPooling2D(pool_size = (2,2))\n",
    "# For more information about the MaxPooling2D function, see https://keras.io/layers/pooling/\n",
    "cnn_model.add(pool_layer2)\n",
    "\n",
    "# Feel free to add more convolution layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Flatten the inout data\n",
    "\n",
    "    * We need to flatten the input data from the previous convolution and pooling layers before putting into the densely connected NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Adding Dense Layers and compile the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 821,409\n",
      "Trainable params: 821,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Let's 8 fully connected layers for deep learning\n",
    "dense_layer1 = Dense(units = 128, activation = 'relu')\n",
    "dense_layer2 = Dense(units = 64, activation = 'relu')\n",
    "# dense_layer3 = Dense(units = 32, activation = 'relu')\n",
    "# dense_layer4 = Dense(units = 16, activation = 'relu')\n",
    "# dense_layer5 = Dense(units = 8, activation = 'relu')\n",
    "# dense_layer6 = Dense(units = 4, activation = 'relu')\n",
    "# dense_layer7 = Dense(units = 2, activation = 'relu')\n",
    "dense_layer8 = Dense(units = 1, activation = 'sigmoid')\n",
    "\n",
    "cnn_model.add(dense_layer1)\n",
    "cnn_model.add(dense_layer2)\n",
    "# cnn_model.add(dense_layer3)\n",
    "# cnn_model.add(dense_layer4)\n",
    "# cnn_model.add(dense_layer5)\n",
    "# cnn_model.add(dense_layer6)\n",
    "# cnn_model.add(dense_layer7)\n",
    "cnn_model.add(dense_layer8)\n",
    "\n",
    "cnn_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "250/250 [==============================] - 100s 401ms/step - loss: 0.6640 - acc: 0.5995 - val_loss: 0.6223 - val_acc: 0.6685\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 104s 417ms/step - loss: 0.6074 - acc: 0.6741 - val_loss: 0.5734 - val_acc: 0.7055\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 101s 405ms/step - loss: 0.5491 - acc: 0.7188 - val_loss: 0.5484 - val_acc: 0.7175\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 92s 367ms/step - loss: 0.5246 - acc: 0.7344 - val_loss: 0.5117 - val_acc: 0.7515\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 96s 384ms/step - loss: 0.4894 - acc: 0.7604 - val_loss: 0.5058 - val_acc: 0.7475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xdf75533ba8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchsize = 32\n",
    "\n",
    "cnn_model.fit_generator(train_data_processed,\n",
    "                        steps_per_epoch = train_data_processed.samples/batchsize, \n",
    "                        epochs = 5, \n",
    "                        validation_data = test_data_processed , \n",
    "                        validation_steps = test_data_processed.samples/batchsize)\n",
    "\n",
    "# Ways to improve accuracy: (a) reduce batch size; (b) increase number of epochs; \n",
    "# (c) increase number of convolutional layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
