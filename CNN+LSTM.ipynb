{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN + LSTM for analysing imdb dataset for simple sentimental analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "U-szRyivJxVz",
    "outputId": "a60845bd-1e07-4c67-ae23-067ca5e8258d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# import imdb dataset\n",
    "from keras.datasets import imdb\n",
    "max_words = 20000\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\",\n",
    "                                                      num_words=None,\n",
    "                                                      skip_top=0,\n",
    "                                                      maxlen=None,\n",
    "                                                      seed=113,\n",
    "                                                      start_char=1,\n",
    "                                                      oov_char=2,\n",
    "                                                      index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IlbGns6FM49F"
   },
   "outputs": [],
   "source": [
    "# pre-processing dataset\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "maxlen = 1000\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = maxlen) # pads sequences to same length\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = maxlen) # pads sequences to same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "colab_type": "code",
    "id": "_PNMhvfiNbp8",
    "outputId": "b2ffbafd-2b67-4b40-cab7-2803d9b46c9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 996, 64)           41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 249, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 70)                37800     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 71        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,638,895\n",
      "Trainable params: 2,638,895\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# setting up model (combination of CNN + LSTM)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense, LSTM, Conv1D, MaxPooling1D, Embedding, Activation\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# transforms positive integers (indexes) into dense vectors of fixed size\n",
    "# Embedding layer must always be used as the first layer\n",
    "model.add(Embedding(max_words, 128, input_length = maxlen))\n",
    "model.add(Dropout(0.3))\n",
    "# add your 1D convolution layer (e.g. temporal convolution)\n",
    "model.add(Conv1D(filters = 64,\n",
    "                 kernel_size = 5,\n",
    "                 padding = 'valid',\n",
    "                 activation = 'relu',\n",
    "                 strides = 1))\n",
    "# add maximum pooling operation for temporal data\n",
    "model.add(MaxPooling1D(pool_size = 4))\n",
    "# add LSTM layer\n",
    "model.add(LSTM(units = 70))\n",
    "# add dense layer - 1 target\n",
    "model.add(Dense(units = 1))\n",
    "# activation function\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wV2fwywJPmv4"
   },
   "outputs": [],
   "source": [
    "# model compilation\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "Fpqn3NAGNT6o",
    "outputId": "873acf4b-105d-43c1-d394-85d9cd22b9e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 413s 21ms/step - loss: 0.3581 - acc: 0.8461 - val_loss: 0.3011 - val_acc: 0.8778\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 807s 40ms/step - loss: 0.2004 - acc: 0.9222 - val_loss: 0.3231 - val_acc: 0.8670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fad16cc7c50>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model fitting\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size = 32,\n",
    "          epochs = 2,\n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "xPI98nCUQfJz",
    "outputId": "1b8bc317-e435-4af6-ee07-ecd7cce80811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am happy\n",
      "\n",
      "i\n",
      "am\n",
      "happy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.3840828]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting a full complete sentence to index form (part of sentimental analysis)\n",
    "word_to_id = imdb.get_word_index()\n",
    "\n",
    "sad_sentences = 'I am very depressed and upset'\n",
    "happy_sentences = 'I am very happy and excited'\n",
    "compiled_sentences = list()\n",
    "compiled_sentences.append(sad_sentences)\n",
    "compiled_sentences.append(happy_sentences)\n",
    "\n",
    "sentence = str(input())\n",
    "temp_list = list()\n",
    "print('')\n",
    "for word in sentence.split(' '):\n",
    "  print(word)\n",
    "  temp_list.append(word_to_id[word])\n",
    "temp_list_padded = sequence.pad_sequences ([temp_list], maxlen = maxlen)\n",
    "model.predict(temp_list_padded)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN+LSTM.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
