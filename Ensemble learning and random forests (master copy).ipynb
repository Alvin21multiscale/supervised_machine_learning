{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble learning and random forests (1 Mar 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "\n",
    "    * A group of predictors is called as ensemble. Eg) logistic regression + voting classifier + random forest classifier\n",
    "    * Random forest is a group of decision tree classifiers\n",
    "    * Types of ensemble methods:\n",
    "        * voting classifier\n",
    "        * bagging and pasting\n",
    "        * boosting (Adaboost, Gradient boosting)\n",
    "        * random forest\n",
    "        \n",
    "\n",
    "2. Advantages of Ensemble Learning\n",
    "\n",
    "\n",
    "\n",
    "3. Disadvantages of Ensemble Learning\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Voting Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# define respective models\n",
    "logistic_model = LogisticRegression()\n",
    "rf_model = RandomForestClassifier()\n",
    "svm_model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1:LogisticRegression 0.4895\n",
      "#1:RandomForestClassifier 0.508\n",
      "#1:SVC 0.4855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1:VotingClassifier 0.485\n",
      "#2:LogisticRegression 0.495\n",
      "#2:RandomForestClassifier 0.4845\n",
      "#2:SVC 0.4835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2:VotingClassifier 0.496\n",
      "#3:LogisticRegression 0.4855\n",
      "#3:RandomForestClassifier 0.4985\n",
      "#3:SVC 0.5075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#3:VotingClassifier 0.494\n",
      "#4:LogisticRegression 0.486\n",
      "#4:RandomForestClassifier 0.5025\n",
      "#4:SVC 0.5005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#4:VotingClassifier 0.4995\n",
      "#5:LogisticRegression 0.4965\n",
      "#5:RandomForestClassifier 0.498\n",
      "#5:SVC 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#5:VotingClassifier 0.494\n",
      "#6:LogisticRegression 0.4805\n",
      "#6:RandomForestClassifier 0.5095\n",
      "#6:SVC 0.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#6:VotingClassifier 0.479\n",
      "#7:LogisticRegression 0.4985\n",
      "#7:RandomForestClassifier 0.497\n",
      "#7:SVC 0.4985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#7:VotingClassifier 0.491\n",
      "#8:LogisticRegression 0.5185\n",
      "#8:RandomForestClassifier 0.491\n",
      "#8:SVC 0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#8:VotingClassifier 0.508\n",
      "#9:LogisticRegression 0.494\n",
      "#9:RandomForestClassifier 0.491\n",
      "#9:SVC 0.5005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#9:VotingClassifier 0.491\n",
      "#10:LogisticRegression 0.485\n",
      "#10:RandomForestClassifier 0.5005\n",
      "#10:SVC 0.484\n",
      "#10:VotingClassifier 0.481\n",
      "[[0.4895, 0.508, 0.4855, 0.485], [0.495, 0.4845, 0.4835, 0.496], [0.4855, 0.4985, 0.5075, 0.494], [0.486, 0.5025, 0.5005, 0.4995], [0.4965, 0.498, 0.497, 0.494], [0.4805, 0.5095, 0.492, 0.479], [0.4985, 0.497, 0.4985, 0.491], [0.5185, 0.491, 0.512, 0.508], [0.494, 0.491, 0.5005, 0.491], [0.485, 0.5005, 0.484, 0.481]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# handling of dataset\n",
    "noise_list = [round((value*0.1),3) for value in range(1,11)]\n",
    "mainlist_accuracy = []\n",
    "counter = 1\n",
    "for value in noise_list:\n",
    "    dataset = make_moons(n_samples=10000, \n",
    "                         shuffle=True, \n",
    "                         noise= value, \n",
    "                         random_state=None)\n",
    "    x_train, x_test = train_test_split(dataset[0], test_size = 0.2)\n",
    "    y_train, y_test = train_test_split(dataset[1], test_size = 0.2)\n",
    "    voting_model = VotingClassifier(\n",
    "                estimators = [('log',logistic_model),('rf',rf_model),('svc',svm_model)],\n",
    "                voting = 'hard') # voting can be 'hard' or 'soft' \n",
    "                                 # 'soft' voting predicts the class \n",
    "                                 # with the highest class \n",
    "                                 # probability and averaged over all \n",
    "                                 # individual classifiers\n",
    "                                 # expected to be more accurate than 'hard' voting\n",
    "    sublist_accuracy = []\n",
    "    for model in (logistic_model,rf_model,svm_model,voting_model):\n",
    "        model.fit(x_train,y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        value_accuracy = accuracy_score(y_pred,y_test)\n",
    "        print('#' + str(counter) + ':' + model.__class__.__name__,value_accuracy)\n",
    "        sublist_accuracy.append(value_accuracy)\n",
    "    mainlist_accuracy.append(sublist_accuracy)\n",
    "    counter += 1\n",
    "print(mainlist_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Bagging and Pasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Objective of bagging and pasting is again to use very different training algorithms. This time, we, however, use the same training algorithm for every predictor but to train them on different random subsets of the training set. \n",
    "\n",
    "* Bagging refers to sampling with replacement, whereas pasting is sampling without replacement.\n",
    "    \n",
    "* Both bagging and pasting allow training instances to be sampled several times across multipple predictors, whereas bagging allows training instances to be sampled several times for the same predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# define respective models\n",
    "logistic_model = LogisticRegression()\n",
    "rf_model = RandomForestClassifier()\n",
    "svm_model = SVC()\n",
    "bagging_model = BaggingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier 0.496\n",
      "BaggingClassifier 0.4865\n",
      "BaggingClassifier 0.5145\n",
      "BaggingClassifier 0.4955\n",
      "BaggingClassifier 0.5045\n",
      "BaggingClassifier 0.508\n",
      "BaggingClassifier 0.5025\n",
      "BaggingClassifier 0.504\n",
      "BaggingClassifier 0.527\n",
      "BaggingClassifier 0.511\n",
      "[0.496, 0.4865, 0.5145, 0.4955, 0.5045, 0.508, 0.5025, 0.504, 0.527, 0.511]\n"
     ]
    }
   ],
   "source": [
    "# handling of dataset + model training\n",
    "noise_list = [round((value*0.1),3) for value in range(1,11)]\n",
    "mainlist_accuracy = []\n",
    "for value in noise_list:\n",
    "    dataset = make_moons(n_samples=10000, \n",
    "                         shuffle=True, \n",
    "                         noise= value, \n",
    "                         random_state=None)\n",
    "    x_train, x_test = train_test_split(dataset[0], test_size = 0.2)\n",
    "    y_train, y_test = train_test_split(dataset[1], test_size = 0.2)\n",
    "    bagging_model = BaggingClassifier(logistic_model, \n",
    "                                      n_estimators=10, \n",
    "                                      max_samples=100, \n",
    "                                      bootstrap=True,\n",
    "                                      n_jobs =-1)\n",
    "                                 # n_estimators is the number of the selected models \n",
    "                                 # Eg. logistic regression, \n",
    "                                 # random forest classifier, SVC etc.\n",
    "                                 # bootstrap = True -> set to bagging. \n",
    "                                 # If False, set to pasting\n",
    "    bagging_model.fit(x_train,y_train)\n",
    "    y_pred = bagging_model.predict(x_test)\n",
    "    value_accuracy = accuracy_score(y_pred,y_test)\n",
    "    print(bagging_model.__class__.__name__,value_accuracy)\n",
    "    mainlist_accuracy.append(value_accuracy)\n",
    "print(mainlist_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random forest is an ensemble of decision trees. \n",
    "* Random forest is generally trained via the bagging method whereby the max samples is set to the size of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.4885\n",
      "RandomForestClassifier 0.5065\n",
      "RandomForestClassifier 0.5015\n",
      "RandomForestClassifier 0.508\n",
      "RandomForestClassifier 0.5\n",
      "RandomForestClassifier 0.494\n",
      "RandomForestClassifier 0.49\n",
      "RandomForestClassifier 0.5005\n",
      "RandomForestClassifier 0.4835\n",
      "RandomForestClassifier 0.498\n",
      "[0.4885, 0.5065, 0.5015, 0.508, 0.5, 0.494, 0.49, 0.5005, 0.4835, 0.498]\n"
     ]
    }
   ],
   "source": [
    "noise_list = [round((value*0.1),3) for value in range(1,11)]\n",
    "mainlist_accuracy = []\n",
    "for value in noise_list:\n",
    "    dataset = make_moons(n_samples=10000, \n",
    "                         shuffle=True, \n",
    "                         noise= value, \n",
    "                         random_state=None)\n",
    "    x_train, x_test = train_test_split(dataset[0], test_size = 0.2)\n",
    "    y_train, y_test = train_test_split(dataset[1], test_size = 0.2)\n",
    "    rf_model = RandomForestClassifier(n_estimators=1000, \n",
    "                                      max_leaf_nodes=32, \n",
    "                                      n_jobs =-1)\n",
    "    rf_model.fit(x_train,y_train)\n",
    "    y_pred = rf_model.predict(x_test)\n",
    "    value_accuracy = accuracy_score(y_pred,y_test)\n",
    "    print(rf_model.__class__.__name__,value_accuracy)\n",
    "    mainlist_accuracy.append(value_accuracy)\n",
    "print(mainlist_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier 0.4865\n",
      "ExtraTreesClassifier 0.51\n",
      "ExtraTreesClassifier 0.5045\n",
      "ExtraTreesClassifier 0.4965\n",
      "ExtraTreesClassifier 0.5105\n",
      "ExtraTreesClassifier 0.5035\n",
      "ExtraTreesClassifier 0.4895\n",
      "ExtraTreesClassifier 0.506\n",
      "ExtraTreesClassifier 0.4985\n",
      "ExtraTreesClassifier 0.5055\n",
      "[0.4865, 0.51, 0.5045, 0.4965, 0.5105, 0.5035, 0.4895, 0.506, 0.4985, 0.5055]\n"
     ]
    }
   ],
   "source": [
    "# using extra-trees -> likewise trades more bias for a lower variance, trains faster than the \n",
    "# regular random forests\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "noise_list = [round((value*0.1),3) for value in range(1,11)]\n",
    "mainlist_accuracy = []\n",
    "for value in noise_list:\n",
    "    dataset = make_moons(n_samples=10000, shuffle=True, noise= value, random_state=None)\n",
    "    x_train, x_test = train_test_split(dataset[0], test_size = 0.2)\n",
    "    y_train, y_test = train_test_split(dataset[1], test_size = 0.2)\n",
    "    rf_model = ExtraTreesClassifier(n_estimators=1000, \n",
    "                                      max_leaf_nodes=32, \n",
    "                                      n_jobs =-1)\n",
    "    rf_model.fit(x_train,y_train)\n",
    "    y_pred = rf_model.predict(x_test)\n",
    "    value_accuracy = accuracy_score(y_pred,y_test)\n",
    "    print(rf_model.__class__.__name__,value_accuracy)\n",
    "    mainlist_accuracy.append(value_accuracy)\n",
    "print(mainlist_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* An ensemble method which combines several weak learners into a strong learner\n",
    "* Generally, the boosting methods train predictors sequentially by trying to correct its predecessor\n",
    "* Most popular boosting methods are AdaBoost and gradient boosting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d)i) AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AdaBoost corrects its predecessor by paying more attention to the training instances that the predecessor underfitted -> results in new predictors by focusing more and more on the hard cases\n",
    "* Building an AdaBoost classifier:\n",
    "    * train the first base classifier (decision tree etc.) and make predictions on the training set\n",
    "    * increase the relative weights of misclassified training instances then train the second classifier using the updated weights and make predictions on the training set again, and update the weights again\n",
    "    * continue the process based on pre-defined iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier 0.4775\n",
      "ExtraTreesClassifier 0.504\n",
      "ExtraTreesClassifier 0.507\n",
      "ExtraTreesClassifier 0.473\n",
      "ExtraTreesClassifier 0.483\n",
      "ExtraTreesClassifier 0.4675\n",
      "ExtraTreesClassifier 0.495\n",
      "ExtraTreesClassifier 0.5125\n",
      "ExtraTreesClassifier 0.4965\n",
      "ExtraTreesClassifier 0.4765\n",
      "[0.4775, 0.504, 0.507, 0.473, 0.483, 0.4675, 0.495, 0.5125, 0.4965, 0.4765]\n"
     ]
    }
   ],
   "source": [
    "# example of using AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "noise_list = [round((value*0.1),3) for value in range(1,11)]\n",
    "mainlist_accuracy = []\n",
    "for value in noise_list:\n",
    "    dataset = make_moons(n_samples=10000, shuffle=True, noise= value, random_state=None)\n",
    "    x_train, x_test = train_test_split(dataset[0], test_size = 0.2)\n",
    "    y_train, y_test = train_test_split(dataset[1], test_size = 0.2)\n",
    "    ada_boost_model = AdaBoostClassifier(DecisionTreeClassifier(max_depth = 2),\n",
    "                                      n_estimators = 1000, \n",
    "                                      algorithm = \"SAMME\",\n",
    "                                      learning_rate = 0.1)\n",
    "                                      # In sklearn, the multiclass version of AdaBoost is called\n",
    "                                      # SAMME (Stagewise Additive Modeling using a Multiclass \n",
    "                                      # Exponential loss Function). Another variant of SAMME is\n",
    "                                      # SAMME.R wherey R stands for \"Real\" which relies on class \n",
    "                                      # class probabilities rather than predictions and may perform\n",
    "                                      # better in some cases\n",
    "    \n",
    "    rf_model.fit(x_train,y_train)\n",
    "    y_pred = rf_model.predict(x_test)\n",
    "    value_accuracy = accuracy_score(y_pred,y_test)\n",
    "    print(rf_model.__class__.__name__,value_accuracy)\n",
    "    mainlist_accuracy.append(value_accuracy)\n",
    "print(mainlist_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d)ii) Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Work in same principle as AdaBoost, with the exception that Gradient boosting attempts to fit the new predictor to the residual erros made by the previous predictor\n",
    "* Most suitable for regression analysis by using Gradient Tree Boosting, or Gradient Boosted Regression Trees (GBRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='population_ensemble_learning.csv' mode='r' encoding='cp1252'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alvin\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average error for the validation step is 3.43%.\n",
      "The coefficient of determination (r^2) value from the training step 0.984.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# importing relevant packages, libraries and classes associated with python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('population_ensemble_learning.csv') as f:\n",
    "   print(f)\n",
    "dataset = pd.read_csv('population_ensemble_learning.csv', encoding='cp1252')\n",
    "\n",
    "dummy_index = 0\n",
    "country_name = 'Singapore'\n",
    "for i in range (len(dataset)):\n",
    "    if dataset['Country Name'][i] == country_name:\n",
    "        dummy_index = i\n",
    "\n",
    "start_year = 1960\n",
    "end_year = 2017\n",
    "diff_year = end_year - start_year\n",
    "year_list = []\n",
    "for i in range(diff_year+1):\n",
    "    year = start_year + i\n",
    "    year_list.append(year)\n",
    "\n",
    "data_x = year_list\n",
    "\n",
    "data_y = []\n",
    "for item in data_x:\n",
    "    data_y.append(dataset[str(item)][dummy_index])\n",
    "\n",
    "x_train,x_test,y_train,y_test =  train_test_split(data_x,data_y)\n",
    "\n",
    "x_train = (np.array(x_train))\n",
    "x_train = x_train.reshape(len(x_train),-1)\n",
    "\n",
    "y_train = (np.array(y_train))\n",
    "y_train = y_train.reshape(len(y_train),-1)\n",
    "\n",
    "x_test = (np.array(x_test))\n",
    "x_test = x_test.reshape(len(x_test),-1)\n",
    "\n",
    "y_test = (np.array(y_test))\n",
    "y_test = y_test.reshape(len(y_test),-1)\n",
    "\n",
    "gradient_boost_model = GradientBoostingRegressor(max_depth = 3, n_estimators=200)\n",
    "gradient_boost_model.fit(x_train,y_train)\n",
    "y_pred = gradient_boost_model.predict(x_test)\n",
    "r2_value = r2_score(y_test,y_pred)\n",
    "r2_value = round(r2_value,3)\n",
    "\n",
    "graph1 = plt.plot(x_test,y_test,'o', label = 'World Population' + \" \" + '(predictions)',\n",
    "                  color = 'r')\n",
    "graph2 = plt.plot(x_test,y_pred,'x', label = 'World Population' + \" \"+ '(Raw data)',\n",
    "                  color = 'b')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Population size')\n",
    "plt.title('Model validation')\n",
    "# plt.grid(color='r', linestyle='', linewidth=2)\n",
    "legend = plt.legend()\n",
    "leg_lines = legend.get_lines()\n",
    "leg_texts = legend.get_texts()\n",
    "plt.setp(leg_lines, linewidth=2.0)\n",
    "plt.show()\n",
    "\n",
    "total_error = 0\n",
    "avg_error = 0\n",
    "for i in range(len(y_pred)):\n",
    "    total_error += (abs(y_pred[i]-y_test[i])/min(y_pred[i],y_test[i]))\n",
    "avg_error = (total_error/len(y_pred)) * 100\n",
    "print('The average error for the validation step is ' + str(round(float(avg_error),2)) \\\n",
    "      + '%' + '.')\n",
    "print('The coefficient of determination (r^2) value from the training step ' \\\n",
    "      + str(r2_value) + '.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
